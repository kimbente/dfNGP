{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b9b2890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gpytorch.distributions import MultitaskMultivariateNormal\n",
    "from linear_operator.operators import to_linear_operator\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from utils import make_grid\n",
    "from configs import N_SIDE\n",
    "\n",
    "# attach this to paths since we are running from subfolder\n",
    "subfolder_pre = \"../\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79150bf8",
   "metadata": {},
   "source": [
    "# Visualise tiles\n",
    "\n",
    "This notebook creates all the individual tiles we then use to make plots for the paper in Powerpoint.\n",
    "All plots are saved into respective folders in `\\figures\\`. Figures can be downloaded as a folder to then fill shapes with the corresponding pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2921d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off to protext RAM\n",
    "show_bool = False\n",
    "# Toggle on here\n",
    "# show_bool = True\n",
    "\n",
    "standard_quiver_scale = 47\n",
    "standard_quiver_width = 0.0035\n",
    "# NOTE: branching has smaller magnitude so we need to scale it up: scale is defined inverse\n",
    "branching_quiver_scale = 22\n",
    "deflection_quiver_scale = 35\n",
    "edge_quiver_scale = 37\n",
    "\n",
    "lim_margin = 0.0526 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc6f468",
   "metadata": {},
   "source": [
    "## Defining custom colorscale for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5eac735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAABhCAYAAABGShAtAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAA7NJREFUeJzt3d1ymzAQBlCl08fuk/ZdyvaiGLM2YEgy7szuOTdmZCHJmGQ+i7+PiIgBAEAbP/73AAAAeC8BEACgGQEQAKAZARAAoBkBEACgGQEQAKAZARAAoBkBEACgGQEQAKCZn5dqR4wxxRjTvPwnxogxv87v3cqmVd0pnus/lu3Uj/V7EWPE9PCay+JWNk1jjPXrXG9VFtNWe9O/8cS0LEdM988/5vGOuJfND1NZHqpyq7cs38tynY0259f7A1rW7+V1Y2fd3XoH/T6NfaPNGNvtP7f1ot7Wttr5DPv17tsn1Vm+m4NtevA9LfvPut6VbX9bXr7v/fG8/ow79Q62beys+1TvaJteaOu2V5zen/fqHW3T3XHtf095n1i//1hv1f/I1s9IijPlq4LTbT0UnOnnM2M47OeL4/6WsZ0Y91M/b1jn5djmhUv9bKzzmX6+NLYX7W2WX1jnu8d96u/i5Drv6ucz/0/OtnfUzxhj/IrfG6XPzAACADQjAAJQ3tZMCXQmAAIAlHD+p44ACEB5H/97APAW5/d0ARCA8hwChkwABABoRgAEoDyHgOnBOYAAAM04BxAAgB0CIADluQgEMgEQAKAZARAAoBkBEACgBFcBAwA04ypgAAB2CIAAlOdG0JAJgAAAzQiAAADNCIAAlOdG0JAJgAAAzQiAAJTnIhDIBEAAynMIGDIBEIDyzADSgyeBAMDCDCA9eBIIACzMANLBlR86AiAAQAFXfugIgACU5xAwZAIgAEAzAiAA5TkHEDIBEIDyHAKGTAAEAGhGAAQAaEYABABoRgAEAGhGAAQAaEYABKA8t4GBTAAEACjAs4ABYMV9AOnAs4ABANglAAIAlHB+rlsABAAo4fxBYAEQgPJcBQyZAAhAeS4CgUwABAAowTmAALBwCJgenAMIAMAOARCA8pwDCJkACADQjAAIQHnOAYRMAAQAaEYABABoRgAEoDwXgdDBlf1cAAQAKODKua4CIABAMwIgAEAzAiAA5bkNDGQCIABAMwIgAOW5ChgyARAAoBkBEACgGQEQAKAZARAAoBkBEACgGQEQAKAZARCA8twIGjIBEIDy3AcQMgEQgPLMAEImAAJQnhlAyARAAMozAwiZAAhAeWYAIRMAAQCaEQABKM8hYMgEQADKcwgYMgEQgPLMAEImAAJQnhlAyARAAMozAwjZR0T4YQQA0IgZQACAZgRAAIBmBEAAgGYEQACAZgRAAIBmBEAAgGYEQACAZgRAAIBmBEAAgGb+Ai+4SdlkzUQkAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pink with high sensitivity\n",
    "values = np.array([0., 0.05, 0.1, 0.5, 1.])\n",
    "colors = [\"white\", \"#ffc4e8\", \"#fca4bd\", \"#e22f26\", \"#830025\"]\n",
    "error_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(name = \"error_cmap\", colors = list(zip(values, colors)))\n",
    "\n",
    "gradient = np.linspace(0, 1, 256).reshape(1, -1)\n",
    "gradient = np.vstack([gradient] * 20)  # Make it tall enough to see\n",
    "\n",
    "# Plot the gradient with the custom colormap\n",
    "plt.figure(figsize = (8, 1))\n",
    "plt.imshow(gradient, aspect = 'auto', cmap = error_cmap)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.savefig(f\"cmaps/error.png\", dpi = 100, bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8da24197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all simulation functions\n",
    "from simulate import (\n",
    "    simulate_detailed_branching,\n",
    "    # simulate_detailed_convergence,\n",
    "    simulate_detailed_curve,\n",
    "    simulate_detailed_deflection,\n",
    "    simulate_detailed_edge,\n",
    "    simulate_detailed_ridges,\n",
    ")\n",
    "\n",
    "# Define simulations as a dictionary with names as keys to function objects\n",
    "# alphabectic order here\n",
    "simulations = {\n",
    "    \"branching\": simulate_detailed_branching,\n",
    "    \"curve\": simulate_detailed_curve,\n",
    "    \"deflection\": simulate_detailed_deflection,\n",
    "    \"edge\": simulate_detailed_edge,\n",
    "    \"ridges\": simulate_detailed_ridges,\n",
    "}\n",
    "\n",
    "#############\n",
    "### TRAIN ###\n",
    "#############\n",
    "\n",
    "x_train = torch.load(subfolder_pre + \"data/sim_data/x_train_lines_discretised_0to1.pt\", weights_only = False).float()\n",
    "\n",
    "# Storage dictionaries\n",
    "y_train_dict = {}\n",
    "\n",
    "# Make y_train_dict: Iterate over all simulation functions\n",
    "for sim_name, sim_func in simulations.items():\n",
    "\n",
    "    # Generate training observations with sim_func\n",
    "    y_train = sim_func(x_train)\n",
    "    # Store training data in dictionary under sim_name\n",
    "    y_train_dict[sim_name] = y_train \n",
    "\n",
    "############\n",
    "### TEST ###\n",
    "############\n",
    "\n",
    "# Make x_grid\n",
    "_, x_test = make_grid(n_side = N_SIDE)\n",
    "\n",
    "# Storage dictionaries\n",
    "y_test_dict = {}\n",
    "\n",
    "# Make y_test_dict: Iterate over all simulation functions\n",
    "for sim_name, sim_func in simulations.items():\n",
    "\n",
    "    # Generate test observations\n",
    "    y_test = sim_func(x_test)\n",
    "    y_test_dict[sim_name] = y_test  # Store test outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a896c28",
   "metadata": {},
   "source": [
    "# Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c3d3d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.detach()\n",
    "\n",
    "for (sim_name, y_train) in y_train_dict.items():\n",
    "\n",
    "    y_test = y_test_dict[sim_name]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (5, 5))\n",
    "\n",
    "    quiver_scale = standard_quiver_scale\n",
    "    if sim_name == \"branching\":\n",
    "        quiver_scale = branching_quiver_scale\n",
    "    if sim_name == \"deflection\":\n",
    "        quiver_scale = deflection_quiver_scale\n",
    "    if sim_name == \"edge\":\n",
    "        quiver_scale = edge_quiver_scale\n",
    "    \n",
    "    # Plot ground truth test data in black\n",
    "    ax.quiver(x_test[:, 0], x_test[:, 1], y_test[:, 0], y_test[:, 1], \n",
    "              width = standard_quiver_width, scale = quiver_scale, color = \"black\")\n",
    "\n",
    "    # NOTE: WITH LIMS\n",
    "    ax.set_xlim(0 - lim_margin, 1 + lim_margin)\n",
    "    ax.set_ylim(0 - lim_margin, 1 + lim_margin)\n",
    "\n",
    "    # Remove axis labels\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    plt.savefig(f\"ground_truth/{sim_name}.png\", dpi = 300, bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "    if show_bool:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd373a4",
   "metadata": {},
   "source": [
    "# Ground truth + train lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4f38800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read line segements as pd.DataFrame\n",
    "line_segments = pd.read_csv(subfolder_pre + \"data/sim_data/x_train_lines_start_end_0to1.csv\")\n",
    "\n",
    "# Convert line segments to torch tensor, ignoring the column headers\n",
    "line_segments = torch.tensor(line_segments.values)\n",
    "\n",
    "x_train = x_train.detach()\n",
    "x_test = x_test.detach()\n",
    "\n",
    "# Define colors\n",
    "train_line_color = \"#3377ff\"  # Color for tranparent line to indicate training data\n",
    "test_color = \"black\"  # Black for test data\n",
    "\n",
    "for (sim_name, y_train) in y_train_dict.items():\n",
    "\n",
    "    # Extract training and test vectors\n",
    "    y_test = y_test_dict[sim_name]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (5, 5))\n",
    "    \n",
    "    # Iterate over (9) segements:\n",
    "    for i in range(0, line_segments.shape[0]):\n",
    "        ax.plot(\n",
    "            [line_segments[i, 0], line_segments[i, 1]], # (x_start, x_end)\n",
    "            [line_segments[i, 2], line_segments[i, 3]], # (y_start, y_end)\n",
    "            color = train_line_color, alpha = 0.2, linewidth = 4)\n",
    "        \n",
    "    quiver_scale = standard_quiver_scale\n",
    "    if sim_name == \"branching\":\n",
    "        quiver_scale = branching_quiver_scale\n",
    "    if sim_name == \"deflection\":\n",
    "        quiver_scale = deflection_quiver_scale\n",
    "    if sim_name == \"edge\":\n",
    "        quiver_scale = edge_quiver_scale\n",
    "    \n",
    "    # Plot ground truth test data in black\n",
    "    ax.quiver(x_test[:, 0], x_test[:, 1], y_test[:, 0], y_test[:, 1], \n",
    "              color = test_color, label = \"test\", width = standard_quiver_width, scale = quiver_scale)\n",
    "\n",
    "    # NOTE: WITH LIMS\n",
    "    ax.set_xlim(0 - lim_margin, 1 + lim_margin)\n",
    "    ax.set_ylim(0 - lim_margin, 1 + lim_margin)\n",
    "\n",
    "    # Remove axis labels\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    plt.savefig(f\"ground_truth_and_train_lines/{sim_name}.png\", dpi = 300, bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "    if show_bool:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5d633c",
   "metadata": {},
   "source": [
    "# Training vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89fe5d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read line segements as pd.DataFrame\n",
    "line_segments = pd.read_csv(subfolder_pre + \"data/sim_data/x_train_lines_start_end_0to1.csv\")\n",
    "\n",
    "# Convert line segments to torch tensor, ignoring the column headers\n",
    "line_segments = torch.tensor(line_segments.values)\n",
    "\n",
    "x_train = x_train.detach()\n",
    "\n",
    "# Define colors\n",
    "train_line_color = \"#3377ff\"  # Color for tranparent line to indicate training data\n",
    "test_color = \"black\"  # Black for test data\n",
    "\n",
    "for (sim_name, y_train) in y_train_dict.items():\n",
    "\n",
    "    # Extract training and test vectors\n",
    "    y_train = y_train_dict[sim_name]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (5, 5))\n",
    "\n",
    "    quiver_scale = standard_quiver_scale\n",
    "    if sim_name == \"branching\":\n",
    "        quiver_scale = branching_quiver_scale\n",
    "    if sim_name == \"deflection\":\n",
    "        quiver_scale = deflection_quiver_scale\n",
    "    if sim_name == \"edge\":\n",
    "        quiver_scale = edge_quiver_scale\n",
    "    \n",
    "    # Plot ground truth test data in black\n",
    "    ax.quiver(x_train[:, 0], x_train[:, 1], y_train[:, 0], y_train[:, 1], \n",
    "              color = test_color, label = \"test\", width = standard_quiver_width, scale = quiver_scale)\n",
    "\n",
    "    # NOTE: WITH LIMS\n",
    "    ax.set_xlim(0 - lim_margin, 1 + lim_margin)\n",
    "    ax.set_ylim(0 - lim_margin, 1 + lim_margin)\n",
    "\n",
    "    # Remove axis labels\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    plt.savefig(f\"train_lines/{sim_name}.png\", dpi = 300, bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "    if show_bool:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cc25a8",
   "metadata": {},
   "source": [
    "# Errors\n",
    "\n",
    "Plot and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b972f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 sims x 5 models = 25\n",
    "for sim_name, sim_func in simulations.items():\n",
    "\n",
    "    # Extract gt\n",
    "    y_test = y_test_dict[sim_name].detach().cpu()  # shape: (N_SIDE^2, 2)\n",
    "\n",
    "    X = x_test[:, 0].reshape(N_SIDE, N_SIDE).detach()\n",
    "    Y = x_test[:, 1].reshape(N_SIDE, N_SIDE).detach()\n",
    "\n",
    "    for model_name in [\"dfNN\", \"dfGP\", \"dfNGP\", \"PINN\", \"GP\"]:\n",
    "        if model_name in [\"dfGP\", \"dfNGP\", \"GP\"]:\n",
    "            path = subfolder_pre + \"results_sim/\" + model_name + \"/\" + sim_name + \"_\" + model_name + \"_test_mean_predictions.pt\"\n",
    "        else:\n",
    "            path = subfolder_pre + \"results_sim/\" + model_name + \"/\" + sim_name + \"_\" + model_name + \"_test_predictions.pt\"\n",
    "\n",
    "        pred = torch.load(path, weights_only = False).detach().cpu()\n",
    "        error = torch.abs(pred - y_test) # shape: (N_SIDE^2, 2)\n",
    "        \n",
    "        # error over both dims for background color\n",
    "        error_magnitude = error.sum(dim = -1).reshape(N_SIDE, N_SIDE)\n",
    "\n",
    "        U = error[:, 0].reshape(N_SIDE, N_SIDE)  # x-component\n",
    "        V = error[:, 1].reshape(N_SIDE, N_SIDE)  # y-component\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize = (5, 5))\n",
    "        pc = plt.pcolor(X, Y, error_magnitude.detach().numpy(), cmap = error_cmap, shading = \"auto\", vmax = 3.0) # fixed vmax for consistency\n",
    "        plt.quiver(X, Y, U, V, scale = 20, color = \"black\") # fixed scale for consistency\n",
    "        # plt.colorbar(pc, label = \"Error magnitude\")\n",
    "        # plt.title(\"Error Field with Quiver Overlay\")\n",
    "\n",
    "        plt.gca().set_aspect('equal')\n",
    "        plt.gca().set_xticks([])\n",
    "        plt.gca().set_yticks([])\n",
    "\n",
    "        plt.savefig(f\"errors/{sim_name}_{model_name}.png\", dpi = 300, bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "        if show_bool:\n",
    "            plt.show()\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81eb49a",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dad71c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 sims x 5 models = 25\n",
    "for sim_name, sim_func in simulations.items():\n",
    "\n",
    "    # Extract gt\n",
    "    y_test = y_test_dict[sim_name].detach().cpu()  # shape: (N_SIDE^2, 2)\n",
    "\n",
    "    X = x_test[:, 0].reshape(N_SIDE, N_SIDE).detach()\n",
    "    Y = x_test[:, 1].reshape(N_SIDE, N_SIDE).detach()\n",
    "\n",
    "    for model_name in [\"dfNN\", \"dfGP\", \"dfNGP\", \"PINN\", \"GP\"]:\n",
    "        if model_name in [\"dfGP\", \"dfNGP\", \"GP\"]:\n",
    "            path = subfolder_pre + \"results_sim/\" + model_name + \"/\" + sim_name + \"_\" + model_name + \"_test_mean_predictions.pt\"\n",
    "        else:\n",
    "            path = subfolder_pre + \"results_sim/\" + model_name + \"/\" + sim_name + \"_\" + model_name + \"_test_predictions.pt\"\n",
    "\n",
    "        pred = torch.load(path, weights_only = False).detach().cpu()\n",
    "\n",
    "        U = pred[:, 0].reshape(N_SIDE, N_SIDE)  # x-component\n",
    "        V = pred[:, 1].reshape(N_SIDE, N_SIDE)  # y-component\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize = (5, 5))\n",
    "\n",
    "        quiver_scale = standard_quiver_scale\n",
    "        if sim_name == \"branching\":\n",
    "            quiver_scale = branching_quiver_scale\n",
    "        if sim_name == \"deflection\":\n",
    "            quiver_scale = deflection_quiver_scale\n",
    "        if sim_name == \"edge\":\n",
    "            quiver_scale = edge_quiver_scale\n",
    "\n",
    "        plt.quiver(X, Y, U, V, \n",
    "                   width = standard_quiver_width, scale = quiver_scale, color = \"black\") # fixed scale for consistency\n",
    "\n",
    "        plt.gca().set_aspect('equal')\n",
    "        plt.gca().set_xticks([])\n",
    "        plt.gca().set_yticks([])\n",
    "\n",
    "         # NOTE: WITH LIMS\n",
    "        # NOTE: WITH LIMS\n",
    "        ax.set_xlim(0 - lim_margin, 1 + lim_margin)\n",
    "        ax.set_ylim(0 - lim_margin, 1 + lim_margin)\n",
    "\n",
    "        plt.savefig(f\"predictions/{sim_name}_{model_name}.png\", dpi = 300, bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "        if show_bool:\n",
    "            plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647a9d42",
   "metadata": {},
   "source": [
    "# Predictions with errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cefb269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 sims x 5 models = 25\n",
    "for sim_name, sim_func in simulations.items():\n",
    "\n",
    "    # Extract gt\n",
    "    y_test = y_test_dict[sim_name].detach().cpu()  # shape: (N_SIDE^2, 2)\n",
    "\n",
    "    X = x_test[:, 0].reshape(N_SIDE, N_SIDE).detach()\n",
    "    Y = x_test[:, 1].reshape(N_SIDE, N_SIDE).detach()\n",
    "\n",
    "    for model_name in [\"dfNN\", \"dfGP\", \"dfNGP\", \"PINN\", \"GP\"]:\n",
    "        if model_name in [\"dfGP\", \"dfNGP\", \"GP\"]:\n",
    "            path = subfolder_pre + \"results_sim/\" + model_name + \"/\" + sim_name + \"_\" + model_name + \"_test_mean_predictions.pt\"\n",
    "        else:\n",
    "            path = subfolder_pre + \"results_sim/\" + model_name + \"/\" + sim_name + \"_\" + model_name + \"_test_predictions.pt\"\n",
    "\n",
    "        pred = torch.load(path, weights_only = False).detach().cpu()\n",
    "        error = torch.abs(pred - y_test) # shape: (N_SIDE^2, 2)\n",
    "        \n",
    "        # error over both dims for background color\n",
    "        error_magnitude = error.sum(dim = -1).reshape(N_SIDE, N_SIDE)\n",
    "\n",
    "        # quivers are preds now\n",
    "        U = pred[:, 0].reshape(N_SIDE, N_SIDE)  # x-component\n",
    "        V = pred[:, 1].reshape(N_SIDE, N_SIDE)  # y-component\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize = (5, 5))\n",
    "        pc = plt.pcolor(X, Y, error_magnitude.detach().numpy(), cmap = error_cmap, shading = \"auto\", vmax = 3.0) # fixed vmax for consistency\n",
    "        quiver_scale = standard_quiver_scale\n",
    "        if sim_name == \"branching\":\n",
    "            quiver_scale = branching_quiver_scale\n",
    "\n",
    "        plt.quiver(X, Y, U, V, scale = quiver_scale, color = \"black\") # fixed scale for consistency\n",
    "        # plt.colorbar(pc, label = \"Error magnitude\")\n",
    "        # plt.title(\"Error Field with Quiver Overlay\")\n",
    "\n",
    "        plt.gca().set_aspect('equal')\n",
    "        plt.gca().set_xticks([])\n",
    "        plt.gca().set_yticks([])\n",
    "\n",
    "        # NOTE: WITH LIMS\n",
    "        plt.xlim(0 - lim_margin, 1 + lim_margin)\n",
    "        plt.ylim(0 - lim_margin, 1 + lim_margin)\n",
    "\n",
    "        plt.savefig(f\"predictions_with_errors/{sim_name}_{model_name}.png\", dpi = 300, bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "        if show_bool:\n",
    "            plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a0b939",
   "metadata": {},
   "source": [
    "# Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5070f3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAABhCAYAAABGShAtAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAydJREFUeJzt3V1L41AYhdFmmP//l483I5iJYIXo7nv2WlAUKaEXkjzno8mx1loPAABq/El/AAAAfpcABAAoIwABAMoIQACAMgIQAKCMAAQAKCMAAQDKCEAAgDICEACgzN+n33kc15//vz77+3fe69j7H/vVP59j1/w/rH+/r3U83p+HtNb19dnfv/Nex36NY7/653PsfY6d/Hwff37FDCCQ8x5kAJt4NsDSBCAAwE2mjGsFIJAzZagM8KQppzUBCORMGSoDbEYAAjlThsoAmxGAQCftWcVYA84EINDJ6nMVuw3gTAACAJQRgAAAZQQgkGNdjl9iDyCcCUAgJ3lVFgRVjDXgTAACOcmrsiAAiglAICc9A2gWECglALmyWYYGx8MsIFBLAHJlswwAbE0AAgCUEYBAJzsdgB8wZRFNAAKdhpykgVmmbKMXgAAAZQQgAEAZAQh0GrJMA/ATBCCQ40kgABECEMiZslsaYDMCEACgjAAEACgjAIGc5B5Aq89AMQEI5CT3APoSCFBMAAIAlBGAQM6Uh2YCPGnKaU0AAjluAwNsZsppTQACAJQRgAAAZQQgAEAZAQjkTNktDbAZAQjkTNktDbAZAQgAUEYAAgDcZMrOFgEIAHCTKTtbBCAAQBkByNWU4QvzTVkrAdiMAOTKRZkGxjlVjGvhTAACOcmrsnFOFeNaOBOAQCczQkAxAQgAUEYAAjnJdTlLgkAxAQjk2JkPECEAAQDKCEAgJ7kEbPIRKCYAgRy3gQGIEIAAAGUEIABAGQEI5Hg8A0CEAOTKrTkAYGsCkCuzMgCwNQEI5JhtBogQgFy5KAPA1gQgV5aAAWBrAhAAoIwABAAoIwABAMoIQACAMgIQAKCMAAQAKCMAgRy3HAI2M+W0JgABAG4y5VkKAhDImXKmBNiMAAQAKCMAgV4mIIFSAhDoNWSzNsDdBCAAQBkBCOQk75dg+RcoJgCBnOS3gC3/AsUEIABAGQEIAFBGAAIAlBGAQCdfAgGKHWt5FhMAQBMzgAAAZQQgAEAZAQgAUEYAAgCUEYAAAGUEIABAGQEIAFBGAAIAlBGAAABl3gDA2ErWDulMxQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values = np.array([0.0, 0.5, 1.])\n",
    "colors = [\"red\", \"white\", \"blue\"]\n",
    "div_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(name = \"red_white_blue\", colors = list(zip(values, colors)))\n",
    "\n",
    "gradient = np.linspace(0, 1, 256).reshape(1, -1)\n",
    "gradient = np.vstack([gradient] * 20)  # Make it tall enough to see\n",
    "\n",
    "# Plot the gradient with the custom colormap\n",
    "plt.figure(figsize = (8, 1))\n",
    "plt.imshow(gradient, aspect = 'auto', cmap = div_cmap)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.savefig(f\"cmaps/divergence.png\", dpi = 100, bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cd8c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 sims x 5 models = 25\n",
    "for sim_name, sim_func in simulations.items():\n",
    "\n",
    "    # Extract gt\n",
    "    y_test = y_test_dict[sim_name].detach().cpu()  # shape: (N_SIDE^2, 2)\n",
    "\n",
    "    X = x_test[:, 0].reshape(N_SIDE, N_SIDE).detach()\n",
    "    Y = x_test[:, 1].reshape(N_SIDE, N_SIDE).detach()\n",
    "\n",
    "    for model_name in [\"GP\", \"PINN\", \"dfGP\", \"dfNN\", \"dfNGP\"]: \n",
    "        path = subfolder_pre + \"results_sim/\" + model_name + \"/\" + sim_name + \"_\" + model_name + \"_test_prediction_divergence_field.pt\"\n",
    "\n",
    "        div = torch.load(path, weights_only = False).detach().cpu().reshape(N_SIDE, N_SIDE)\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize = (5, 5))\n",
    "        mag = 3.0 # lower so that PINN divergence is more visible\n",
    "        plt.pcolormesh(div, cmap = div_cmap, vmin = - mag, vmax = mag) # fixed scale for consistency\n",
    "\n",
    "        plt.gca().set_aspect('equal')\n",
    "        plt.gca().set_xticks([])\n",
    "        plt.gca().set_yticks([])\n",
    "\n",
    "        plt.savefig(f\"divergence/{sim_name}_{model_name}.png\", dpi = 300, bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "        if show_bool:\n",
    "            plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07299004",
   "metadata": {},
   "source": [
    "# Samples (+ error, + uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3263af10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAABhCAYAAABGShAtAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAnlJREFUeJzt3MFO20AUQFGn6v9/VD4s01UrhPoqUlJqzz1nQ8AmHiQWV8743dZa6wAAIOPb/14AAABfSwACAMQIQACAGAEIABAjAAEAYgQgAECMAAQAiBGAAAAxAhAAIOb7MyevtY611vF4PH69fv/9R49N5/28zu++fub1Z4+/+vf+dm1n+Jum9ZxhbV+9njOvbcf/zVe8x3T8FT/7F++5+xp3u87Zrn2F9VxhjWdbz7TG4ziO+/0+HnvLHUAAgA38KQzfE4AAABu43W4fPlcAAgDECEAAgA34CBgAgJEABADYgD2AAACMBCAAQIwABACIEYAAADECEAAgRgACAMQIQACADRgEDQAQYw4gAAAjAQgAECMAAQBiBCAAQIwABACIEYAAADECEAAgRgACAGzAIGgAgBiDoAEAGAlAAIAYAQgAECMAAQBiBCAAQIwABACIEYAAADECEABgAwZBAwDEGAQNAMBIAAIAxAhAAIAYAQgAECMAAdjeM09HwlV5ChgA3njm6Ui4Kk8BAwAwEoAAADECEAAgRgACAMQIQACAGAEIABAjAAEANmAOIABAjDmAAACMBCAAQIwABACIEYAAABvwEAgAACMBCAAQIwABADZgDAwAQIw9gAAAMe4AAgAwEoAAADECEABgA/YAAgDE2AMIAMBIAAIAxAhAAIAN2AMIABBjDyAAACMBCAAQIwABADZgDyAAQIw9gAAAjAQgAECMAAQAiBGAAAAxAhAAIEYAAgBswBgYAIAYY2AAABgJQACAmNt65gNjAAAuzx1AAIAYAQgAECMAAQBiBCAAQIwABACIEYAAADECEAAgRgACAMQIQACAmB92SGPZOFojFgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make var_cmap \n",
    "values = np.array([0.0, 0.04, 0.5, 1.0])\n",
    "colors = [\"white\", \"#dfdfdf\", \"#797979\", \"#3d3d3d\"]\n",
    "var_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(name = \"var_cmap\", colors = list(zip(values, colors)))\n",
    "\n",
    "# Plot the gradient with the custom colormap\n",
    "plt.figure(figsize = (8, 1))\n",
    "plt.imshow(gradient, aspect = 'auto', cmap = var_cmap)\n",
    "plt.axis('off')\n",
    "plt.savefig(f\"cmaps/variance.png\", dpi = 100, bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8968ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 sims x 4 models = 20\n",
    "for sim_name, sim_func in simulations.items():\n",
    "\n",
    "    # Extract gt\n",
    "    y_test = y_test_dict[sim_name].detach().cpu()  # shape: (N_SIDE^2, 2)\n",
    "\n",
    "    X = x_test[:, 0].reshape(N_SIDE, N_SIDE).detach()\n",
    "    Y = x_test[:, 1].reshape(N_SIDE, N_SIDE).detach()\n",
    "\n",
    "    for model_name in [\"GP\", \"dfGP\", \"dfGPcm\", \"dfNGP\"]:\n",
    "        mean_path = subfolder_pre + \"results_sim/\" + model_name + \"/\" + sim_name + \"_\" + model_name + \"_test_mean_predictions.pt\"\n",
    "        covar_path = subfolder_pre + \"results_sim/\" + model_name + \"/\" + sim_name + \"_\" + model_name + \"_test_covar_predictions.pt\"\n",
    "\n",
    "        mean = torch.load(mean_path, weights_only = False).detach().cpu()\n",
    "        covar = torch.load(covar_path, weights_only = False).detach().cpu()\n",
    "\n",
    "        # Access gpytorch dist\n",
    "        distribution = MultitaskMultivariateNormal(\n",
    "             mean, to_linear_operator(covar))\n",
    "        \n",
    "        n_samples = 3\n",
    "\n",
    "        ### Uncertainty ###\n",
    "        # 20 x 20\n",
    "        # NOTE: Interleaved structure\n",
    "        var = torch.diag(covar)[0::2].reshape(N_SIDE, N_SIDE) + torch.diag(covar)[1::2].reshape(N_SIDE, N_SIDE)\n",
    "\n",
    "        ##################\n",
    "        ### 1. Samples ###\n",
    "        ##################\n",
    "        for i in range(n_samples):\n",
    "            sample = distribution.rsample()\n",
    "\n",
    "            U = sample[:, 0]\n",
    "            V = sample[:, 1]\n",
    "\n",
    "            plt.figure(figsize = (5, 5))\n",
    "\n",
    "            ### Plot samples ###\n",
    "            quiver_scale = standard_quiver_scale\n",
    "            if sim_name == \"branching\":\n",
    "                quiver_scale = branching_quiver_scale\n",
    "            if sim_name == \"deflection\":\n",
    "                quiver_scale = deflection_quiver_scale\n",
    "            if sim_name == \"edge\":\n",
    "                quiver_scale = edge_quiver_scale\n",
    "                \n",
    "            plt.quiver(X, Y, U, V, \n",
    "                       scale = quiver_scale, width = standard_quiver_width, color = \"black\") \n",
    "            # fixed scale for consistency\n",
    "            \n",
    "            plt.gca().set_aspect('equal')\n",
    "            plt.gca().set_xticks([])\n",
    "            plt.gca().set_yticks([])\n",
    "\n",
    "            # NOTE: WITH LIMS\n",
    "            plt.xlim(0 - lim_margin, 1 + lim_margin)\n",
    "            plt.ylim(0 - lim_margin, 1 + lim_margin)\n",
    "\n",
    "            plt.savefig(f\"samples/{sim_name}_{model_name}_sample_{i}.png\", dpi = 300, bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "            if show_bool:\n",
    "                plt.show()\n",
    "            plt.close()\n",
    "\n",
    "            ##########################\n",
    "            ### 2. Samples + error ###\n",
    "            ##########################\n",
    "            error = torch.abs(sample - y_test)\n",
    "        \n",
    "            # error over both dims for background color\n",
    "            error_magnitude = error.sum(dim = -1).reshape(N_SIDE, N_SIDE)\n",
    "\n",
    "            plt.figure(figsize = (5, 5))\n",
    "\n",
    "            plt.pcolor(X, Y, error_magnitude, cmap = error_cmap, shading = \"auto\", vmax = 3.0)\n",
    "            # NOTE: quiver scale already selected in loop above\n",
    "            plt.quiver(X, Y, U, V, scale = quiver_scale, width = standard_quiver_width, color = \"black\") # fixed scale for consistency\n",
    "\n",
    "            plt.gca().set_aspect('equal')\n",
    "            plt.gca().set_xticks([])\n",
    "            plt.gca().set_yticks([])\n",
    "\n",
    "            # NOTE: WITH LIMS\n",
    "            plt.xlim(0 - lim_margin, 1 + lim_margin)\n",
    "            plt.ylim(0 - lim_margin, 1 + lim_margin)\n",
    "\n",
    "            plt.savefig(f\"samples_with_error/{sim_name}_{model_name}_sample_{i}.png\", dpi = 300, bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "            if show_bool:\n",
    "                plt.show()\n",
    "            plt.close()\n",
    "\n",
    "            ################################\n",
    "            ### 3. Samples + uncertainty ###\n",
    "            ################################\n",
    "\n",
    "            plt.figure(figsize = (5, 5))\n",
    "\n",
    "            mag = 0.2 # increase so it does not saturate\n",
    "\n",
    "            # Var extracted above\n",
    "            plt.pcolormesh(X, Y, var, cmap = var_cmap, vmax = mag, vmin = 0)\n",
    "            plt.quiver(X, Y, U, V, scale = quiver_scale, width = standard_quiver_width, color = \"black\") # fixed scale for consistency\n",
    "\n",
    "            plt.gca().set_aspect('equal')\n",
    "            plt.gca().set_xticks([])\n",
    "            plt.gca().set_yticks([])\n",
    "\n",
    "            # NOTE: WITH LIMS\n",
    "            plt.xlim(0 - lim_margin, 1 + lim_margin)\n",
    "            plt.ylim(0 - lim_margin, 1 + lim_margin)\n",
    "\n",
    "            plt.savefig(f\"samples_with_uncertainty/{sim_name}_{model_name}_sample_{i}.png\", dpi = 300, bbox_inches = 'tight', pad_inches = 0)\n",
    "\n",
    "            if show_bool:\n",
    "                plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45f4373",
   "metadata": {},
   "source": [
    "# Variance (i.e. uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7c03413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP\n",
      "dfGP\n",
      "dfGPcm\n",
      "dfNGP\n",
      "GP\n",
      "dfGP\n",
      "dfGPcm\n",
      "dfNGP\n",
      "GP\n",
      "dfGP\n",
      "dfGPcm\n",
      "dfNGP\n",
      "GP\n",
      "dfGP\n",
      "dfGPcm\n",
      "dfNGP\n",
      "GP\n",
      "dfGP\n",
      "dfGPcm\n",
      "dfNGP\n"
     ]
    }
   ],
   "source": [
    "# 5 sims x 4 models = 20\n",
    "for sim_name, sim_func in simulations.items():\n",
    "\n",
    "    # Extract gt\n",
    "    y_test = y_test_dict[sim_name].detach().cpu()  # shape: (N_SIDE^2, 2)\n",
    "\n",
    "    X = x_test[:, 0].reshape(N_SIDE, N_SIDE).detach()\n",
    "    Y = x_test[:, 1].reshape(N_SIDE, N_SIDE).detach()\n",
    "\n",
    "    for model_name in [\"GP\", \"dfGP\", \"dfGPcm\", \"dfNGP\"]:\n",
    "        mean_path = subfolder_pre + \"results_sim/\" + model_name + \"/\" + sim_name + \"_\" + model_name + \"_test_mean_predictions.pt\"\n",
    "        covar_path = subfolder_pre + \"results_sim/\" + model_name + \"/\" + sim_name + \"_\" + model_name + \"_test_covar_predictions.pt\"\n",
    "\n",
    "        mean = torch.load(mean_path, weights_only = False).detach().cpu()\n",
    "        covar = torch.load(covar_path, weights_only = False).detach().cpu()\n",
    "\n",
    "        # Access gpytorch dist\n",
    "        distribution = MultitaskMultivariateNormal(\n",
    "             mean, to_linear_operator(covar))\n",
    "        \n",
    "        n_samples = 3\n",
    "\n",
    "        # Select every second element starting at index 0 or 1 \n",
    "        # NOTE: Interleaved structure\n",
    "        var = torch.diag(covar)[0::2].reshape(N_SIDE, N_SIDE) + torch.diag(covar)[1::2].reshape(N_SIDE, N_SIDE)\n",
    "        \n",
    "        plt.figure(figsize = (5, 5))\n",
    "        mag = 0.2 # increase so it does not saturate\n",
    "        plt.pcolormesh(var, cmap = var_cmap, vmax = mag, vmin = 0) # fixed scale for consistency, cmap = var_cmap\n",
    "\n",
    "        plt.gca().set_aspect('equal')\n",
    "        plt.gca().set_xticks([])\n",
    "        plt.gca().set_yticks([])\n",
    "\n",
    "        plt.savefig(f\"variance/{sim_name}_{model_name}.png\", dpi = 300, bbox_inches = 'tight', pad_inches = 0)\n",
    "        print(model_name)\n",
    "        if show_bool:\n",
    "            plt.show()\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfngp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
